{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from lib import data_prep, feature_extraction, models\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "font = {\n",
    "    \"family\": \"sans-serif\",\n",
    "    \"weight\": \"bold\",\n",
    "    \"size\": 12\n",
    "}\n",
    "matplotlib.rc(\"font\", **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Base directory\n",
    "data_loc = os.path.join(os.getcwd(), \"DATA\")\n",
    "\n",
    "# file name\n",
    "file_names = {\n",
    "    0: \"machine_ON_no-ref_start-error_1.csv\",  # Machine turned ON, and the parameter switch enable error\n",
    "    1: \"machine_ON_no-ref_start-error_2.csv\",\n",
    "    2: \"machine_ON_no-ref_start-error_3.csv\",\n",
    "    3: \"machine_ON_no-ref_start-error_4.csv\",\n",
    "    4: \"machine_ON_ref_no-error_1.csv\",  # Machine ON referenced and no-error idling\n",
    "    5: \"machine_ON_ref_no-error_2.csv\",  # Machine ON referenced and no-error idling\n",
    "    6: \"machine_ON_ref_no-error_3.csv\",\n",
    "    7: \"machine_ON_ref_no-error_4.csv\",\n",
    "    8: \"machine_ON_ref_no-error_5.csv\",\n",
    "    9: \"machine_ON_ref_no-error_6.csv\",\n",
    "    10: \"machine_ON_ref_overtravel-error_x_neg_1.csv\",  # Machine ON referenced and Overtravel for X negative\n",
    "    11: \"machine_ON_ref_overtravel-error_x_pos_1.csv\",  # Machine ON referenced and Overtravel for X positive\n",
    "    12: \"machine_ON_no-ref_overtravel-error_x_neg_1.csv\",  # Machine ON not-referenced and Overtravel for X negative\n",
    "    13: \"machine_ON_no-ref_overtravel-error_x_pos_1.csv\", # Machine ON not-referenced and Overtravel for X positive\n",
    "    14: \"machine_ON_ref_overtravel-error_x_neg_axes-extreme_1.csv\",\n",
    "    15: \"machine_ON_ref_overtravel-error_y_neg_axes-extreme_1.csv\",  # Machine ON referenced and Overtravel for Y negative\n",
    "    16: \"machine_ON_ref_overtravel-error_y_neg_1.csv\", # Machine and ON referenced and Overtravel in Y\n",
    "    17: \"machine_ON_ref_overtravel-error_y_pos_1.csv\",  # Machine ON referenced and Overtravel for Y positive\n",
    "    18: \"machine_ON_ref_overtravel-error_z_neg_1.csv\",  # Machine ON referenced and Overtravel for Z negative\n",
    "    19: \"machine_ON_ref_overtravel-error_z_pos_1.csv\",  # Machine ON referenced and Overtravel for Z positive\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Segmentation\n",
    "\n",
    "- Keeping the segmentation window consistent here at 60s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "segment_secs = 60\n",
    "wavelet_nperseg = 15"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dont choose \"no\" and \"sample_time\" as they will be added later to the beginning\n",
    "# Chosen - Choosing only the active power sum of all three phases\n",
    "chosen_cols = [\"Power1\", \"Power2\", \"Power3\", \"PowerReac1\", \"PowerReac2\", \"PowerReac3\", \"PowerApp1\", \"PowerApp2\", \"PowerApp3\"]\n",
    "# chosen_cols = [\"PowerSum\", 'PowerReacSum', 'PowerAppSum']\n",
    "# chosen_cols = [\"PowerSum\"]\n",
    "segmented_data = {}\n",
    "for index, file_name in file_names.items():\n",
    "    path = os.path.join(data_loc, file_name)\n",
    "    temp = data_prep.segment_data(file_name=path, col_names=chosen_cols, segment_secs=segment_secs)\n",
    "    # Remove the sample_time col\n",
    "    temp = temp[:, 1:, :]\n",
    "    segmented_data[file_name] =  temp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print to ensure that segmentation is successful\n",
    "for file_name in segmented_data.keys():\n",
    "\n",
    "    sys.stdout.write(f\"For the file-{file_name} the shape-{segmented_data[file_name].shape}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Associations between the classes and the files in this study\n",
    "class_file_association = {\n",
    "    \"on-ref\": [\"machine_ON_ref_no-error_1.csv\", \"machine_ON_ref_no-error_2.csv\", \"machine_ON_ref_no-error_3.csv\", \"machine_ON_ref_no-error_4.csv\", \"machine_ON_ref_no-error_5.csv\", \"machine_ON_ref_no-error_6.csv\"],\n",
    "\n",
    "    \"on-noref-error\": [\"machine_ON_no-ref_start-error_1.csv\", \"machine_ON_no-ref_start-error_2.csv\", \"machine_ON_no-ref_start-error_3.csv\", \"machine_ON_no-ref_start-error_4.csv\"],\n",
    "\n",
    "    \"overtravel-x\": [\"machine_ON_ref_overtravel-error_x_neg_1.csv\", \"machine_ON_ref_overtravel-error_x_pos_1.csv\", \"machine_ON_no-ref_overtravel-error_x_neg_1.csv\", \"machine_ON_no-ref_overtravel-error_x_pos_1.csv\", \"machine_ON_ref_overtravel-error_x_neg_axes-extreme_1.csv\"],\n",
    "\n",
    "    \"overtravel-y\": [\"machine_ON_ref_overtravel-error_y_neg_1.csv\", \"machine_ON_ref_overtravel-error_y_pos_1.csv\",\n",
    "                    \"machine_ON_ref_overtravel-error_y_neg_axes-extreme_1.csv\"],\n",
    "    \"overtravel-z\": [\"machine_ON_ref_overtravel-error_z_neg_1.csv\", \"machine_ON_ref_overtravel-error_z_pos_1.csv\"],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_segmented_data = {}\n",
    "for class_instance in class_file_association.keys():\n",
    "    for index, file_name in enumerate(class_file_association[class_instance]):\n",
    "\n",
    "        if index == 0:\n",
    "            class_segmented_data[class_instance] = segmented_data[file_name]\n",
    "        else:\n",
    "            class_segmented_data[class_instance] = np.append(class_segmented_data[class_instance], segmented_data[file_name], axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reshape the data appropriately\n",
    "for class_instance in class_segmented_data.keys():\n",
    "    class_segmented_data[class_instance] = np.transpose(class_segmented_data[class_instance], (2, 1, 0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print to ensure that the files have been loaded correctly\n",
    "for class_instance in class_segmented_data.keys():\n",
    "\n",
    "    sys.stdout.write(f\"The class-{class_instance} has the shape-{class_segmented_data[class_instance].shape}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Extraction\n",
    "- Time domain\n",
    "- Frequency Domain\n",
    "- Time-frequency domain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_dataset_features = {}\n",
    "for class_instance in class_segmented_data.keys():\n",
    "    dataset_features = []\n",
    "    for row in class_segmented_data[class_instance]:\n",
    "        computed_features = []\n",
    "        for col in row:\n",
    "            freq_args = [{\"axis\": 0}, {\"axis\": 0}, {\"axis\": 0, \"nperseg\": 30}]\n",
    "            freq_time_args = [{\"wavelet\": \"db1\"}, {\"wavelet\": \"db1\"}, {\"wavelet\": \"db1\"}]\n",
    "            computed_features += feature_extraction.compute_all_features(col, freq_args=freq_args, freq_time_args=freq_time_args)\n",
    "\n",
    "        # Append to a list\n",
    "        dataset_features.append(computed_features)\n",
    "\n",
    "    # Add to class instance\n",
    "    class_dataset_features[class_instance] = np.array(dataset_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sys.stdout.write(\"After feature extraction process\\n\\n\")\n",
    "for class_instance in class_dataset_features.keys():\n",
    "\n",
    "    sys.stdout.write(f'For the class-{class_instance} , the extracted features has the shape={class_dataset_features[class_instance].shape}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate training data\n",
    "- One shot training, no K-fold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_label_associations = {\n",
    "    \"on-ref\": 0,\n",
    "    \"off\": 1,\n",
    "    \"on-noref-error\": 2,\n",
    "    \"overtravel-x\": 3,\n",
    "    \"overtravel-y\": 4,\n",
    "    \"overtravel-z\": 5\n",
    "}\n",
    "for index, class_instance in enumerate(class_dataset_features.keys()):\n",
    "\n",
    "    temp_X = class_dataset_features[class_instance]\n",
    "    temp_y = np.repeat(class_label_associations[class_instance], temp_X.shape[0])[:, np.newaxis]\n",
    "\n",
    "    if index == 0:\n",
    "        X = temp_X\n",
    "        y = temp_y\n",
    "    else:\n",
    "        X = np.append(X, temp_X, axis=0)\n",
    "        y = np.append(y, temp_y, axis=0)\n",
    "\n",
    "# Shuffle the dataset\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "# To a vector format\n",
    "y =  np.squeeze(y)\n",
    "\n",
    "sys.stdout.write(f\"The final combined shape-{X.shape}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting into training and testing data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normalization if required\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model development\n",
    "\n",
    "- Only a single model was developed\n",
    "- The model was SVM as it had the best performance in this scenario"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Selected best hyper-parameters\n",
    "model_params = {'LogisticRegression': {'max_iter': 5000, 'multi_class': 'multinomial', 'n_jobs': 4, 'tol': 0.0001, \"class_weight\": \"balanced\"},\n",
    " 'DecisionTreeClassifier': {'class_weight': 'balanced', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 100},\n",
    " 'KNeighborsClassifier': {'n_neighbors': 20},\n",
    " 'SVC': {'class_weight': 'balanced', 'kernel': 'linear', 'tol': 1e-07},\n",
    " 'BaggingClassifier': {'n_estimators': 50},\n",
    " 'RandomForestClassifier': {'class_weight': 'balanced', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 100, 'n_estimators': 200}}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create repo of models\n",
    "models_repo = models.Models()\n",
    "# Initialize the models\n",
    "models_repo.create_models(model_params)\n",
    "\n",
    "# Train the models\n",
    "models_repo.train_models(X_train, y_train, verbose=True)\n",
    "\n",
    "# Score the models\n",
    "if len(chosen_cols) == 1:\n",
    "    sys.stdout.write(f\"When only considering the data column {chosen_cols[0]}\\n\")\n",
    "for model_name in models_repo.trained_model_dict.keys():\n",
    "    sys.stdout.write(f\"Score for the model-{model_name} is {models_repo.trained_model_dict[model_name].score(X_test, y_test)}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section all the features are considered while creating the feature importance plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Names of each of the extracted features\n",
    "feature_names = [\n",
    "    \"rms\",\n",
    "    \"variance\",\n",
    "    \"peak value\",\n",
    "    \"crest factor\",\n",
    "    \"kurtosis fisher\",\n",
    "    \"clearance factor\",\n",
    "    \"impulse factor\",\n",
    "    \"shape factor\",\n",
    "    \"line integral\",\n",
    "    \"peak to peak\",\n",
    "    \"skewness\",\n",
    "    \"peak fft\",\n",
    "    \"energy fft\",\n",
    "    \"PSD fft\",\n",
    "    \"WPD-1 energy\",\n",
    "    \"WPD-2 energy\",\n",
    "    \"WPD-3 energy\"\n",
    "]\n",
    "\n",
    "combined_features = []\n",
    "for main_feature in chosen_cols:\n",
    "    for feature_name in feature_names:\n",
    "        combined_features.append(main_feature + \" | \" + feature_name)\n",
    "\n",
    "feature_names = combined_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To see how long it takes\n",
    "feature_importance_results = {}\n",
    "importances_mean = {}\n",
    "importances_std = {}\n",
    "start_time = time.time()\n",
    "for model_name in models_repo.trained_model_dict.keys():\n",
    "    clf = models_repo.trained_model_dict[model_name]\n",
    "    feature_importance_results[model_name] = permutation_importance(clf, X_test, y_test, n_repeats=100, random_state=42, n_jobs=8)\n",
    "    # Importances mean and std\n",
    "    importances_mean[model_name] = feature_importance_results[model_name].importances_mean\n",
    "    importances_std[model_name] = feature_importance_results[model_name].importances_std\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Time elapsed is {elapsed_time}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig = plt.figure(figsize=(15, 60))\n",
    "axs = fig.subplots(6, 1)\n",
    "plot_model_names = list(importances_mean.keys())\n",
    "index = 0\n",
    "\n",
    "# Subplots\n",
    "for row in range(6):\n",
    "\n",
    "    axs[row].bar(feature_names, importances_mean[plot_model_names[index]], width=0.5, yerr=importances_std[plot_model_names[index]])\n",
    "    axs[row].set_xticks(range(len(feature_names)))\n",
    "    axs[row].set_xticklabels(feature_names, rotation=90)\n",
    "\n",
    "    # Set labels etc\n",
    "    axs[row].set_title(f\"Feature Importance using permutation on {plot_model_names[index]}\")\n",
    "    axs[row].set_ylabel(\"Decrease in mean accuracy\")\n",
    "\n",
    "    index = index + 1\n",
    "\n",
    "# For some spacing\n",
    "fig.tight_layout(pad=1.0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Identifying the common contributors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Selected features\n",
    "\n",
    "Plotting only the features that were manually selected"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Top k features\n",
    "\n",
    "Selecting and plotting the top 5 important features from all"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top = 10\n",
    "\n",
    "# Select the importances mean and std\n",
    "selected_importances_mean = {}\n",
    "selected_importances_std = {}\n",
    "selected_names = {}\n",
    "for model_name in importances_mean.keys():\n",
    "    maxk_indices = np.squeeze(np.argpartition(importances_mean[model_name], -top)[-top:])\n",
    "    # get items\n",
    "    selected_importances_mean[model_name] = importances_mean[model_name][maxk_indices]\n",
    "    selected_importances_std[model_name] = importances_std[model_name][maxk_indices]\n",
    "\n",
    "    # Get top names\n",
    "    selected_names[model_name] = np.array(feature_names)[maxk_indices]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reset fonts\n",
    "font = {\n",
    "    \"family\": \"sans-serif\",\n",
    "    \"weight\": \"bold\",\n",
    "    \"size\": 12\n",
    "}\n",
    "matplotlib.rc(\"font\", **font)\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(15, 60))\n",
    "axs = fig.subplots(6, 1)\n",
    "plot_model_names = list(importances_mean.keys())\n",
    "index = 0\n",
    "\n",
    "# Subplots\n",
    "for row in range(6):\n",
    "\n",
    "    axs[row].bar(selected_names[plot_model_names[index]], selected_importances_mean[plot_model_names[index]], width=0.5,  yerr=selected_importances_std[plot_model_names[index]])\n",
    "    axs[row].set_xticks(range(len(selected_names[plot_model_names[index]])))\n",
    "    axs[row].set_xticklabels(selected_names[plot_model_names[index]], rotation=90)\n",
    "\n",
    "    # Set labels etc\n",
    "    axs[row].set_title(f\"Feature Importance using permutation on {plot_model_names[index]}\")\n",
    "    axs[row].set_ylabel(\"Decrease in mean accuracy\")\n",
    "\n",
    "    index = index + 1\n",
    "\n",
    "# For some spacing\n",
    "fig.tight_layout(pad=4.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Identifying the top contributors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k = 10\n",
    "model_names = list(importances_mean.keys())\n",
    "energy_features = []\n",
    "extracted_features = []\n",
    "for model_name in importances_mean.keys():\n",
    "\n",
    "    # Get the maximum-k for each model\n",
    "    maxk_influences_indices = np.argpartition(importances_mean[model_name], -k)[-k:]\n",
    "    # Get the features\n",
    "    maxk_feature_names = np.array(feature_names)[maxk_influences_indices]\n",
    "\n",
    "    # Split the maxk feature names\n",
    "    for feature_name in maxk_feature_names:\n",
    "        splits = feature_name.split(\"|\")\n",
    "        energy_features.append(splits[0].strip())\n",
    "        extracted_features.append(splits[1].strip())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Count the common contributors\n",
    "counted_energy_features = Counter(energy_features)\n",
    "counted_extracted_features = Counter(extracted_features)\n",
    "\n",
    "# histogram on the counts\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "axs = fig.subplots(1, 2)\n",
    "axs[0].bar(counted_energy_features.keys(), counted_energy_features.values(), width=0.8, color=\"darkgreen\")\n",
    "axs[1].bar(counted_extracted_features.keys(), counted_extracted_features.values(), width=0.5, color=\"darkgreen\")\n",
    "axs[1].set_xticklabels(counted_extracted_features.keys(), rotation=90)\n",
    "axs[0].set_xticklabels(counted_energy_features.keys(), rotation=90)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}